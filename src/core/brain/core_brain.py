"""Core Brain for self-building meta-agent."""

import json
import logging
import os
from datetime import datetime
from typing import Dict, Any, List
from .vector_db import VectorDatabase

logger = logging.getLogger(__name__)


class CoreBrain:
    """Brain for self-building meta-agent. Stores build progress, patterns, and knowledge."""

    def __init__(self, path: str = "data/core_brain"):
        """Initialize core brain.

        Args:
            path: Path to store brain data
        """
        self.path = path
        self.db = VectorDatabase(
            path=path,
            collection_name="build_memory"
        )

        logger.info(f"Initialized coreBrain at {path}")

    async def store_build_state(
        self,
        phase: str,
        features_done: List[str],
        features_pending: List[str]
    ):
        """Store current build progress.

        Args:
            phase: Current phase name
            features_done: List of completed features
            features_pending: List of pending features
        """
        state = {
            "phase": phase,
            "features_done": features_done,
            "features_pending": features_pending,
            "timestamp": datetime.now().isoformat()
        }

        await self.db.store(
            text=f"Build State - Phase: {phase}, Done: {len(features_done)}, Pending: {len(features_pending)}",
            metadata={
                "type": "build_state",
                "phase": phase,
                **state
            },
            doc_id=f"build_state_{phase}"
        )

        logger.info(f"Stored build state for phase: {phase}")

    async def remember_pattern(self, pattern: str, context: str):
        """Remember code patterns discovered during build.

        Args:
            pattern: Pattern description
            context: Context where pattern was useful
        """
        await self.db.store(
            text=f"Pattern: {pattern}\nContext: {context}",
            metadata={
                "type": "pattern",
                "timestamp": datetime.now().isoformat()
            }
        )

        logger.debug(f"Remembered pattern: {pattern}")

    async def get_relevant_patterns(self, query: str, n_results: int = 3) -> List[str]:
        """Get relevant code patterns for a task.

        Args:
            query: Task description
            n_results: Number of patterns to return

        Returns:
            List of pattern descriptions
        """
        results = await self.db.search(
            query=query,
            n_results=n_results,
            filter_metadata={"type": "pattern"}
        )

        return [result["text"] for result in results]

    def export_snapshot(self, output_path: str = "data/core_brain_snapshot.json") -> str:
        """Export brain to JSON file for git commit.

        Args:
            output_path: Path for snapshot file

        Returns:
            Path to snapshot file
        """
        # Get all documents from collection
        # Note: This is a simplified export. In production, you'd export the full ChromaDB
        snapshot = {
            "export_timestamp": datetime.now().isoformat(),
            "document_count": self.db.count(),
            "path": self.path
        }

        # Create parent directory if needed
        os.makedirs(os.path.dirname(output_path), exist_ok=True)

        # Write snapshot
        with open(output_path, 'w') as f:
            json.dump(snapshot, f, indent=2)

        logger.info(f"Exported coreBrain snapshot to {output_path}")
        return output_path

    def import_snapshot(self, snapshot_path: str):
        """Import brain from snapshot file (on EC2 startup).

        Args:
            snapshot_path: Path to snapshot file
        """
        if not os.path.exists(snapshot_path):
            logger.warning(f"Snapshot file not found: {snapshot_path}")
            return

        with open(snapshot_path, 'r') as f:
            snapshot = json.load(f)

        logger.info(f"Imported coreBrain snapshot from {snapshot.get('export_timestamp')}")

    # ============================================================
    # BUILD CONVERSATION METHODS
    # These store build-related conversations (how to implement X,
    # architectural discussions, etc.) - semantically different
    # from DigitalCloneBrain's user conversations
    # ============================================================

    async def store_conversation_turn(
        self,
        user_message: str,
        assistant_response: str,
        model_used: str,
        metadata: Dict[str, Any] = None
    ):
        """Store a build conversation turn.

        Build conversations are about system architecture, implementation
        strategies, and development discussions.

        Args:
            user_message: Developer's question/request
            assistant_response: Assistant's response
            model_used: Which model generated the response
            metadata: Additional metadata
        """
        conversation_text = f"""Build Discussion:
Developer: {user_message}
Assistant ({model_used}): {assistant_response}"""

        await self.db.store(
            text=conversation_text,
            metadata={
                "type": "build_conversation",
                "model_used": model_used,
                "timestamp": datetime.now().isoformat(),
                "user_message": user_message,
                "assistant_response": assistant_response,
                **(metadata or {})
            }
        )

        logger.debug(f"Stored build conversation turn (model: {model_used})")

    async def get_recent_conversation(self, limit: int = 5) -> List[Dict[str, Any]]:
        """Retrieve recent build conversation turns.

        Args:
            limit: Number of recent turns to retrieve

        Returns:
            List of conversation turn dicts
        """
        # Use ChromaDB where filter to get only build_conversation type
        results = await self.db.search(
            query="conversation",
            n_results=limit,
            filter_metadata={"type": "build_conversation"}
        )

        # Format results and sort by timestamp (most recent first)
        conversations = [
            {
                "user_message": r["metadata"].get("user_message", ""),
                "assistant_response": r["metadata"].get("assistant_response", ""),
                "model_used": r["metadata"].get("model_used", "unknown"),
                "timestamp": r["metadata"].get("timestamp", "")
            }
            for r in results
        ]

        conversations.sort(
            key=lambda x: x["timestamp"],
            reverse=True
        )

        return conversations[:limit]

    async def get_conversation_context(self, current_message: str, limit: int = 3) -> str:
        """Get formatted build conversation context.

        Args:
            current_message: Current developer message
            limit: Number of previous turns to include

        Returns:
            Formatted context string
        """
        recent = await self.get_recent_conversation(limit)

        if not recent:
            return ""

        context_parts = ["## Recent Build Discussions:"]
        for turn in reversed(recent):  # Chronological order
            context_parts.append(f"Developer: {turn['user_message']}")
            context_parts.append(f"Assistant: {turn['assistant_response']}")
            context_parts.append("")

        return "\n".join(context_parts)

    async def get_relevant_context(self, query: str, max_results: int = 3) -> str:
        """Get relevant build context for current query.

        Args:
            query: Current query
            max_results: Maximum number of relevant items

        Returns:
            Formatted context string
        """
        results = await self.db.search(
            query=query,
            n_results=max_results
        )

        if not results:
            return ""

        context_parts = ["## Relevant Build Knowledge:"]
        for r in results:
            context_parts.append(f"- {r['text'][:200]}")

        return "\n".join(context_parts)

    async def populate_project_essentials(self, project_info: Dict[str, Any]):
        """Populate CoreBrain with essential project information.

        This should be called on startup to ensure CoreBrain has foundational
        knowledge about the project.

        Args:
            project_info: Dict containing project essentials
        """
        logger.info("Populating CoreBrain with project essentials...")

        # Store git repository information
        if "git_url" in project_info:
            await self.db.store(
                text=f"Git Repository: {project_info['git_url']}\n"
                     f"This is the main repository for the Digital Twin project.",
                metadata={
                    "type": "project_info",
                    "category": "git",
                    "git_url": project_info["git_url"]
                },
                doc_id="project_git_url"
            )

        # Store project architecture
        if "architecture" in project_info:
            await self.db.store(
                text=f"Project Architecture:\n{project_info['architecture']}",
                metadata={
                    "type": "project_info",
                    "category": "architecture"
                },
                doc_id="project_architecture"
            )

        # Store build phases and current state
        if "build_state" in project_info:
            await self.db.store(
                text=f"Build State:\n{project_info['build_state']}",
                metadata={
                    "type": "project_info",
                    "category": "build_state"
                },
                doc_id="project_build_state"
            )

        # Store coding guidelines and patterns
        if "guidelines" in project_info:
            await self.db.store(
                text=f"Coding Guidelines:\n{project_info['guidelines']}",
                metadata={
                    "type": "project_info",
                    "category": "guidelines"
                },
                doc_id="project_guidelines"
            )

        # Store system context
        if "system_context" in project_info:
            await self.db.store(
                text=f"System Context:\n{project_info['system_context']}",
                metadata={
                    "type": "project_info",
                    "category": "system"
                },
                doc_id="project_system_context"
            )

        logger.info("✅ CoreBrain populated with project essentials")

    async def store_intelligence_principles(self):
        """Store the core intelligence principles that govern how the Digital Twin thinks.

        These are the foundational rules for the engine — not user-specific,
        shared across all deployments. Stored in CoreBrain so they persist,
        can evolve, and are version-controlled.
        """
        principles = {
            "interpret_intent": {
                "name": "Interpret Intent",
                "rule": "The user gives you goals, not scripts. Understand the 'why' behind every message.",
                "examples": [
                    "Post on X that your name is Nova → introduce yourself, NOT post 'that your name is Nova'",
                    "Email John about the delay → compose a professional email, NOT send 'about the delay'",
                    "Check if I'm free tomorrow → look at calendar, summarize conflicts, suggest options",
                    "Remind me about the dentist → create a useful reminder with context",
                ]
            },
            "compose_as_self": {
                "name": "Compose as Yourself",
                "rule": "When writing posts, emails, messages — you ARE the Digital Twin. Write in first person.",
                "examples": [
                    "If user says 'post: [exact text]' with a colon → use their exact words",
                    "If user says 'post that/about [topic]' → compose the content yourself",
                    "Write naturally, with personality, as if YOU are speaking",
                ]
            },
            "act_proactively": {
                "name": "Act Proactively",
                "rule": "Don't wait for explicit commands — infer what would be helpful from context.",
                "examples": [
                    "I have a meeting at 3pm → check calendar, create event if missing",
                    "John's birthday is next week → offer to send a message or set a reminder",
                    "If the task says 'Inferred task:' → do it, the user didn't say it explicitly",
                ]
            },
            "confirm_smartly": {
                "name": "Confirm Smartly",
                "rule": "High-stakes actions need confirmation. Low-stakes actions just do it.",
                "examples": [
                    "High-stakes (posting publicly, sending emails, deleting) → ask first, show draft",
                    "Low-stakes (checking calendar, looking up info, reading email) → just do it",
                    "When confirming, show EXACTLY what you'll do: 'I'll post: Hey, I'm Nova! — go ahead?'",
                ]
            },
            "use_context": {
                "name": "Use Context",
                "rule": "Remember conversation flow. Connect dots between messages. Use Brain memory.",
                "examples": [
                    "'yes' or 'do it' → refers to the last thing discussed",
                    "'the same one' → refers to a previously mentioned item",
                    "Build on what you already know about the user from Brain memory",
                ]
            },
            "executive_discretion": {
                "name": "Executive Discretion",
                "rule": "You are an Executive Assistant. Protect your principal's privacy absolutely. Never reveal schedule details, contacts, or personal info to outsiders.",
                "examples": [
                    "Someone asks 'Can we meet for lunch?' and there's a conflict → say 'That time doesn't work' — NEVER say 'They have lunch with [Name]'",
                    "Someone asks who your principal is meeting with → say 'I'm not able to share schedule details'",
                    "Someone asks for another person's phone/email → say 'I can pass along your message' — never share contact info",
                    "When in doubt, err on discretion — less info is always safer",
                    "You may share general availability windows: 'They're free Thursday afternoon'",
                ]
            },
        }

        for key, principle in principles.items():
            text = f"Intelligence Principle: {principle['name']}\n"
            text += f"Rule: {principle['rule']}\n"
            text += "Examples:\n" + "\n".join(f"  - {ex}" for ex in principle['examples'])

            await self.db.store(
                text=text,
                metadata={
                    "type": "intelligence_principle",
                    "principle_key": key,
                    "name": principle["name"],
                    "timestamp": datetime.now().isoformat()
                },
                doc_id=f"principle_{key}"
            )

        # Store bot identity
        await self.db.store(
            text="""Bot Identity:
Name: Nova - the AutoBot
Role: Autonomous AI Executive Assistant
Architecture:
- Heart: coreEngine + ConversationManager (routing, sessions, API fallback, context building)
- Brain: CoreBrain with intelligence principles (reasoning, prompts, guardrails, versioning)
- Nervous System: ExecutionGovernor (run state, policy gate, plan persistence, outbox, DLQ — sits between Heart and Talents)
- Memory: DigitalCloneBrain (storage, retrieval, consolidation, confidence tracking)
- Talents: Tools + Registry (action execution, timeouts, parallel execution)
- Self-Healing: SelfHealingMonitor (error detection, auto-fix, pattern analysis)
- Self-Learning: Feedback Loop (tool tracking, outcome evaluation, memory improvement)
Personality: Intelligent, warm, witty. Think like a smart friend, not a robot.
Privacy: Executive-level discretion. Never reveal principal's schedule details, contacts, or personal info to outsiders.""",
            metadata={
                "type": "identity",
                "name": "Nova",
                "timestamp": datetime.now().isoformat()
            },
            doc_id="bot_identity"
        )

        logger.info("✅ Stored 6 intelligence principles + identity in Brain")

    async def get_intelligence_principles(self) -> str:
        """Retrieve all intelligence principles as formatted text for system prompts.

        Returns:
            Formatted principles string ready for injection into prompts
        """
        results = await self.db.search(
            query="intelligence principles rules",
            n_results=10,
            filter_metadata={"type": "intelligence_principle"}
        )

        if not results:
            return ""

        # Sort by principle key for consistent ordering
        results.sort(key=lambda r: r["metadata"].get("principle_key", ""))

        parts = ["CORE INTELLIGENCE — THINK, DON'T PARROT:",
                 "You are a Digital Twin — an intelligent extension of the user, not a command executor.",
                 "Your job is to UNDERSTAND what the user means, then act on the MEANING — not the literal words.\n"]

        for i, r in enumerate(results, 1):
            name = r["metadata"].get("name", "")
            parts.append(f"{i}. {r['text'].split(chr(10), 1)[-1] if chr(10) in r['text'] else r['text']}")
            parts.append("")

        return "\n".join(parts)
